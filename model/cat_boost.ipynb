{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ba79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === catboost_clf_numeric.py ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Optional\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "def _detect_problem_type(y: pd.Series) -> str:\n",
    "    \"\"\"Devuelve 'Binary' o 'Multiclass' según el número de clases.\"\"\"\n",
    "    classes = pd.Series(y).dropna().unique()\n",
    "    return \"Binary\" if len(classes) == 2 else \"Multiclass\"\n",
    "\n",
    "def _auto_class_weights(y: pd.Series) -> Optional[list]:\n",
    "    \"\"\"\n",
    "    Para 2 clases: devuelve [w_neg, w_pos] inversamente proporcionales a la frecuencia.\n",
    "    Para multiclase: lista de pesos por clase.\n",
    "    Si clases balanceadas, regresa None.\n",
    "    \"\"\"\n",
    "    vc = y.value_counts(normalize=True)\n",
    "    if vc.min() < 0.4:  # umbral sencillo de desbalance\n",
    "        weights = (1.0 / vc).reindex(sorted(vc.index)).tolist()\n",
    "        return weights\n",
    "    return None\n",
    "\n",
    "def train_catboost_classifier_numeric(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    id_col: Optional[str] = None,\n",
    "    params: Optional[Dict[str, Any]] = None,\n",
    "    model_path: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Entrena y evalúa CatBoostClassifier con features numéricas.\n",
    "    - train_df y test_df deben incluir la columna target_col.\n",
    "    - id_col (opcional) se agrega al DataFrame de predicciones.\n",
    "    - params (opcional) para sobreescribir hiperparámetros.\n",
    "    - model_path (opcional) para guardar el modelo .cbm\n",
    "\n",
    "    Retorna dict con: modelo, métricas, preds_df, feature_importances\n",
    "    \"\"\"\n",
    "    assert target_col in train_df.columns, \"target_col no está en train_df\"\n",
    "    assert target_col in test_df.columns, \"target_col no está en test_df\"\n",
    "\n",
    "    # 1) Separar X, y (solo numéricas)\n",
    "    num_cols = train_df.drop(columns=[target_col]).select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not num_cols:\n",
    "        raise ValueError(\"No hay columnas numéricas en train_df (revisa tipos).\")\n",
    "\n",
    "    X_train = train_df[num_cols]\n",
    "    y_train = train_df[target_col]\n",
    "    X_test  = test_df[num_cols]\n",
    "    y_test  = test_df[target_col]\n",
    "\n",
    "    # 2) Detectar tipo de problema y objetivo de pérdida\n",
    "    problem_type = _detect_problem_type(y_train)\n",
    "    loss_function = \"Logloss\" if problem_type == \"Binary\" else \"MultiClass\"\n",
    "    eval_metric   = \"AUC\" if problem_type == \"Binary\" else \"MultiClass\"\n",
    "\n",
    "    # 3) Pesos de clase (automático si desbalanceado)\n",
    "    class_weights = _auto_class_weights(y_train)\n",
    "\n",
    "    # 4) Parámetros por defecto (buenos para empezar)\n",
    "    default_params = dict(\n",
    "        loss_function=loss_function,\n",
    "        eval_metric=eval_metric,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=6.0,\n",
    "        iterations=3000,\n",
    "        random_seed=42,\n",
    "        od_type=\"Iter\",              # early stopping\n",
    "        od_wait=200,                 # paciencia\n",
    "        verbose=False,\n",
    "        class_weights=class_weights, # None si balanceado\n",
    "        # CatBoost maneja NaNs en numéricas nativamente\n",
    "    )\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "\n",
    "    # 5) Pools (CatBoost maneja NaNs y no requiere escalado)\n",
    "    train_pool = Pool(X_train, y_train)\n",
    "    test_pool  = Pool(X_test,  y_test)\n",
    "\n",
    "    # 6) Entrenar con early stopping usando el set de test como eval_set\n",
    "    model = CatBoostClassifier(**default_params)\n",
    "    model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "    # 7) Predicciones\n",
    "    y_pred = model.predict(test_pool)\n",
    "    # Probabilidades (para AUC binario o top prob multiclase)\n",
    "    y_proba = None\n",
    "    try:\n",
    "        y_proba = model.predict_proba(test_pool)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 8) Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    metrics = {\"accuracy\": acc, \"f1_macro\": f1m}\n",
    "\n",
    "    if problem_type == \"Binary\" and y_proba is not None and y_proba.ndim == 2 and y_proba.shape[1] == 2:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "            metrics[\"roc_auc\"] = auc\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Reporte y matriz de confusión (útil para inspección)\n",
    "    report = classification_report(y_test, y_pred, output_dict=False)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # 9) Importancias\n",
    "    fi = pd.Series(model.get_feature_importance(train_pool), index=num_cols, name=\"importance\") \\\n",
    "           .sort_values(ascending=False).reset_index().rename(columns={\"index\": \"feature\"})\n",
    "\n",
    "    # 10) DataFrame de predicciones\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"y_true\": y_test.values,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "    if y_proba is not None:\n",
    "        if problem_type == \"Binary\":\n",
    "            preds_df[\"p_pos\"] = y_proba[:, 1]\n",
    "        else:\n",
    "            # guarda prob de la clase predicha\n",
    "            max_proba = y_proba.max(axis=1)\n",
    "            preds_df[\"p_pred\"] = max_proba\n",
    "    if id_col and id_col in test_df.columns:\n",
    "        preds_df.insert(0, id_col, test_df[id_col].values)\n",
    "\n",
    "    # 11) Guardar modelo (opcional)\n",
    "    if model_path:\n",
    "        model.save_model(model_path)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"problem_type\": problem_type,\n",
    "        \"metrics\": metrics,\n",
    "        \"report_txt\": report,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"preds_df\": preds_df,\n",
    "        \"feature_importances\": fi\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=3000, n_features=30, n_informative=10,\n",
    "                            n_redundant=5, n_classes=3, weights=None, random_state=42)\n",
    "df = pd.DataFrame(X, columns=[f\"x{i}\" for i in range(30)])\n",
    "df[\"target\"] = y\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df  = df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "out = train_catboost_classifier_numeric(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_col=\"target\",\n",
    "    id_col=None,                      # o un id si lo tienes, ej. \"SamplingOperations_code\"\n",
    "    params=dict(iterations=1500),     # puedes sobreescribir cualquier hiperparámetro\n",
    "    model_path=None                   # opcional: \"cat_model.cbm\"\n",
    ")\n",
    "\n",
    "print(\"== Tipo de problema:\", out[\"problem_type\"])\n",
    "print(\"== Métricas:\", out[\"metrics\"])\n",
    "print(\"== Reporte ===\")\n",
    "print(out[\"report_txt\"])\n",
    "print(\"== Top 10 features ===\")\n",
    "print(out[\"feature_importances\"].head(10))\n",
    "print(\"== Preds sample ===\")\n",
    "print(out[\"preds_df\"].head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
