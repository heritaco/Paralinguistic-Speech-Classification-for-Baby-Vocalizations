{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7df7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5f688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# %pip install -U pandas numpy scikit-learn pydub opensmile matplotlib joblib\n",
    "\n",
    "from pathlib import Path\n",
    "import glob, numpy as np, pandas as pd, joblib\n",
    "from pydub import AudioSegment, effects as FX\n",
    "import opensmile\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONFIG =================================================================\n",
    "CSV_LABELS = Path(\"data/raw/training_label.csv\")\n",
    "RAW_DIR    = Path(\"data/raw/Training_data\")\n",
    "PROC_DIR   = Path(r\"C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\processed\\Training_data\")\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_SR  = 16_000\n",
    "TARGET_SW  = 2            # 16-bit\n",
    "MAKE_MONO  = True\n",
    "HPF, LPF   = 150, 6000    # Hz\n",
    "GATE_K     = 1.5          # τ = K·RMS\n",
    "NORM_MODE  = \"rms\"        # \"peak\" or \"rms\"\n",
    "TARGET_RMS = 0.1\n",
    "TH_ABSTAIN = 0.55         # abstain if max prob < threshold\n",
    "\n",
    "# Optional mapping if you know numeric→text classes:\n",
    "# CLASS_MAP = {1:\"healthy\", 2:\"asphyxia\", 3:\"hipoacusia\", 4:\"hiperbilirrubinemia\", 5:\"hipotiroidismo\"}\n",
    "CLASS_MAP = None\n",
    "\n",
    "EPS = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c402c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== AUDIO HELPERS ==========================================================\n",
    "def clean_seg(seg: AudioSegment) -> AudioSegment:\n",
    "    if HPF: seg = FX.high_pass_filter(seg, HPF)\n",
    "    if LPF: seg = FX.low_pass_filter(seg, LPF)\n",
    "    return seg\n",
    "\n",
    "def seg_to_float(seg: AudioSegment):\n",
    "    if MAKE_MONO and seg.channels != 1: seg = seg.set_channels(1)\n",
    "    if TARGET_SR   and seg.frame_rate != TARGET_SR: seg = seg.set_frame_rate(TARGET_SR)\n",
    "    if TARGET_SW   and seg.sample_width != TARGET_SW: seg = seg.set_sample_width(TARGET_SW)\n",
    "    sr = seg.frame_rate; sw = seg.sample_width\n",
    "    arr = np.array(seg.get_array_of_samples())\n",
    "    peak = float(1 << (8*sw - 1))  # 32768 for 16-bit\n",
    "    y = arr.astype(np.float32) / peak\n",
    "    return y, sr\n",
    "\n",
    "def gate(y: np.ndarray, k: float) -> np.ndarray:\n",
    "    rms = float(np.sqrt(np.mean(y**2) + EPS))\n",
    "    thr = k * rms\n",
    "    y2 = y.copy()\n",
    "    y2[np.abs(y2) < thr] = 0.0\n",
    "    return y2\n",
    "\n",
    "def normalize(y: np.ndarray, mode: str, target_rms: float) -> np.ndarray:\n",
    "    if mode == \"peak\":\n",
    "        m = float(np.max(np.abs(y)) + EPS); return y / m\n",
    "    rms = float(np.sqrt(np.mean(y**2) + EPS))\n",
    "    y2  = y * (target_rms / rms)\n",
    "    return np.clip(y2, -1.0, 1.0)\n",
    "\n",
    "def float_to_seg(y: np.ndarray, sr: int) -> AudioSegment:\n",
    "    y16 = np.clip(y * 32767.0, -32768, 32767).astype(np.int16)\n",
    "    return AudioSegment(y16.tobytes(), frame_rate=int(sr), sample_width=2, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805fe5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== LOAD LABELS & PROCESS AUDIO ===========================================\n",
    "labels = pd.read_csv(CSV_LABELS)\n",
    "labels[\"nombre_archivo\"] = labels[\"nombre_archivo\"].astype(str)\n",
    "if CLASS_MAP: labels[\"clase_txt\"] = labels[\"clase\"].map(CLASS_MAP)\n",
    "\n",
    "files = sorted(glob.glob(str(RAW_DIR/\"*.wav\")))\n",
    "df = pd.DataFrame({\"path\": files, \"nombre_archivo\": [Path(f).name for f in files]})\n",
    "df = df.merge(labels[[\"nombre_archivo\",\"clase\"]], on=\"nombre_archivo\", how=\"inner\")\n",
    "assert len(df), \"No labeled WAVs found.\"\n",
    "\n",
    "proc_paths, y_numeric = [], []\n",
    "for p, fname, cls in df[[\"path\",\"nombre_archivo\",\"clase\"]].itertuples(index=False, name=None):\n",
    "    seg = AudioSegment.from_file(p)\n",
    "    seg = clean_seg(seg)\n",
    "    y, sr = seg_to_float(seg)\n",
    "    y = gate(y, GATE_K)\n",
    "    y = normalize(y, NORM_MODE, TARGET_RMS)\n",
    "    seg_out = float_to_seg(y, sr)\n",
    "    outp = PROC_DIR / fname\n",
    "    seg_out.export(str(outp), format=\"wav\")\n",
    "    proc_paths.append(str(outp))\n",
    "    y_numeric.append(cls)\n",
    "\n",
    "y = np.array(y_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6181cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== FEATURE EXTRACTION (openSMILE) =========================================\n",
    "# eGeMAPSv02 functionals (88-D) – robust low-dimensional baseline\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "feats = []\n",
    "for wav in proc_paths:\n",
    "    df_feat = smile.process_file(wav)  # 1-row DataFrame\n",
    "    df_feat[\"file\"] = Path(wav).name\n",
    "    feats.append(df_feat.reset_index(drop=True))\n",
    "Xdf = pd.concat(feats, axis=0, ignore_index=True).set_index(\"file\")\n",
    "X = Xdf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1429781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV macro-F1: 0.012131237937689549\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 1  1  0  0  3  0]\n",
      " [ 0 22  0  0  9  0]\n",
      " [ 0  3  1  0  3  0]\n",
      " [ 0  0  0 29  1  0]\n",
      " [ 0  8  1  2 47  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         0\n",
      "           1      0.029     0.200     0.051         5\n",
      "           2      0.000     0.000     0.000        31\n",
      "           3      0.000     0.000     0.000         7\n",
      "           4      0.016     0.033     0.022        30\n",
      "           5      0.000     0.000     0.000        58\n",
      "\n",
      "    accuracy                          0.015       131\n",
      "   macro avg      0.008     0.039     0.012       131\n",
      "weighted avg      0.005     0.015     0.007       131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# ==== MODEL: CALIBRATED LOGISTIC REGRESSION =================================\n",
    "base = make_pipeline(StandardScaler(with_mean=True), LogisticRegression(max_iter=2000, n_jobs=None))\n",
    "clf  = CalibratedClassifierCV(base, method=\"isotonic\", cv=3)  # probability calibration\n",
    "\n",
    "# CV predictions for evaluation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "probs = cross_val_predict(clf, X, y, cv=skf, method=\"predict_proba\", n_jobs=-1)\n",
    "pred  = probs.argmax(1)\n",
    "f1m   = f1_score(y, pred, average=\"macro\")\n",
    "print(\"CV macro-F1:\", f1m)\n",
    "print(confusion_matrix(y, pred))\n",
    "print(classification_report(y, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4981c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infantcry_eGeMAPS_logreg.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on all data and persist\n",
    "clf.fit(X, y)\n",
    "joblib.dump({\"model\": clf, \"columns\": Xdf.columns.tolist(), \"class_map\": CLASS_MAP}, \"infantcry_eGeMAPS_logreg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== INFERENCE WRAPPER WITH ABSTAIN ========================================\n",
    "def predict_wav(path_wav: str, model_bundle_path=\"infantcry_eGeMAPS_logreg.joblib\", theta=TH_ABSTAIN):\n",
    "    seg = AudioSegment.from_file(path_wav)\n",
    "    seg = clean_seg(seg)\n",
    "    y, sr = seg_to_float(seg)\n",
    "    y = gate(y, GATE_K)\n",
    "    y = normalize(y, NORM_MODE, TARGET_RMS)\n",
    "    seg_out = float_to_seg(y, sr)  # optional: overwrite or keep temp\n",
    "    tmp = Path(path_wav).with_suffix(\".proc.wav\"); seg_out.export(str(tmp), format=\"wav\")\n",
    "\n",
    "    mb = joblib.load(model_bundle_path)\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "    xf = smile.process_file(str(tmp))\n",
    "    xf = xf[mb[\"columns\"]].to_numpy()\n",
    "    probs = mb[\"model\"].predict_proba(xf)[0]\n",
    "    k = probs.argmax(); p = probs[k]\n",
    "    label = mb[\"class_map\"].get(k+1, k+1) if mb[\"class_map\"] else int(k+1)  # numeric→text if map provided\n",
    "    return {\"label\": label if p >= theta else \"abstain\", \"p_max\": float(p), \"probs\": probs.tolist()}\n",
    "\n",
    "# ==== TEST INFERENCE =========================================================\n",
    "# Example usage:\n",
    "res = predict_wav(str(proc_paths[0]))\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26520006",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cd274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U pandas numpy scikit-learn pydub opensmile joblib\n",
    "\n",
    "from pathlib import Path\n",
    "import glob, json\n",
    "import numpy as np, pandas as pd, joblib\n",
    "from pydub import AudioSegment, effects as FX\n",
    "import opensmile\n",
    "\n",
    "# ========= CONFIG ============================================================\n",
    "TEST_DIR   = Path(r\"C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\raw\\Testing_data\")\n",
    "OUT_DIR    = Path(r\"C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\processed\\Testing_data\")\n",
    "MODEL_PATH = Path(\"models\\infantcry_eGeMAPS_logreg.joblib\")  # from previous training\n",
    "PRED_CSV   = OUT_DIR / \"predictions_testing.csv\"\n",
    "\n",
    "# Audio processing (must match training)\n",
    "TARGET_SR  = 16_000           # Hz\n",
    "TARGET_SW  = 2                # 16-bit\n",
    "MAKE_MONO  = True\n",
    "HPF, LPF   = 150, 6000        # Hz\n",
    "GATE_K     = 1.5              # gate threshold = K * RMS\n",
    "NORM_MODE  = \"rms\"            # \"peak\" or \"rms\"\n",
    "TARGET_RMS = 0.1\n",
    "TH_ABSTAIN = 0.55\n",
    "EPS        = 1e-12\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= HELPERS ===========================================================\n",
    "def clean_seg(seg: AudioSegment) -> AudioSegment:\n",
    "    if HPF: seg = FX.high_pass_filter(seg, HPF)\n",
    "    if LPF: seg = FX.low_pass_filter(seg, LPF)\n",
    "    return seg\n",
    "\n",
    "def seg_to_float(seg: AudioSegment):\n",
    "    if MAKE_MONO and seg.channels != 1: seg = seg.set_channels(1)\n",
    "    if TARGET_SR   and seg.frame_rate != TARGET_SR: seg = seg.set_frame_rate(TARGET_SR)\n",
    "    if TARGET_SW   and seg.sample_width != TARGET_SW: seg = seg.set_sample_width(TARGET_SW)\n",
    "    sr = seg.frame_rate; sw = seg.sample_width\n",
    "    arr = np.array(seg.get_array_of_samples())\n",
    "    peak = float(1 << (8*sw - 1))  # 32768 for 16-bit\n",
    "    y = arr.astype(np.float32) / peak\n",
    "    return y, sr\n",
    "\n",
    "def gate(y: np.ndarray, k: float) -> np.ndarray:\n",
    "    rms = float(np.sqrt(np.mean(y**2) + EPS))\n",
    "    thr = k * rms\n",
    "    y2 = y.copy()\n",
    "    y2[np.abs(y2) < thr] = 0.0\n",
    "    return y2\n",
    "\n",
    "def normalize(y: np.ndarray, mode: str, target_rms: float) -> np.ndarray:\n",
    "    if mode == \"peak\":\n",
    "        m = float(np.max(np.abs(y)) + EPS)\n",
    "        return y / m\n",
    "    rms = float(np.sqrt(np.mean(y**2) + EPS))\n",
    "    y2  = y * (target_rms / rms)\n",
    "    return np.clip(y2, -1.0, 1.0)\n",
    "\n",
    "def float_to_seg(y: np.ndarray, sr: int) -> AudioSegment:\n",
    "    y16 = np.clip(y * 32767.0, -32768, 32767).astype(np.int16)\n",
    "    return AudioSegment(y16.tobytes(), frame_rate=int(sr), sample_width=2, channels=1)\n",
    "\n",
    "# ========= LOAD MODEL ========================================================\n",
    "bundle = joblib.load(MODEL_PATH)\n",
    "clf      = bundle[\"model\"]                     # CalibratedClassifierCV\n",
    "cols_ref = bundle[\"columns\"]                   # training feature columns order\n",
    "class_map = bundle.get(\"class_map\", None)      # optional numeric->text map\n",
    "classes = clf.classes_.tolist()                # model's class labels (e.g., [1,2,3,4,5])\n",
    "\n",
    "# openSMILE extractor (eGeMAPSv02 Functionals)\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "# ========= PROCESS + FEATURE + PREDICT ======================================\n",
    "wav_paths = sorted(glob.glob(str(TEST_DIR / \"*.wav\")))\n",
    "assert wav_paths, f\"No WAVs found in {TEST_DIR}\"\n",
    "\n",
    "records = []\n",
    "X_rows, idx = [], []\n",
    "\n",
    "for p in wav_paths:\n",
    "    p = Path(p)\n",
    "    # 1) load + clean + gate + normalize\n",
    "    seg = AudioSegment.from_file(str(p))\n",
    "    seg = clean_seg(seg)\n",
    "    y, sr = seg_to_float(seg)\n",
    "    y = gate(y, GATE_K)\n",
    "    y = normalize(y, NORM_MODE, TARGET_RMS)\n",
    "\n",
    "    # 2) save processed wav\n",
    "    seg_out = float_to_seg(y, sr)\n",
    "    out_path = OUT_DIR / p.name\n",
    "    seg_out.export(str(out_path), format=\"wav\")\n",
    "\n",
    "    # 3) extract features on processed wav\n",
    "    feat = smile.process_file(str(out_path))  # 1-row DataFrame\n",
    "    feat[\"file\"] = p.name\n",
    "    X_rows.append(feat.reset_index(drop=True))\n",
    "    idx.append(p.name)\n",
    "\n",
    "# Stack features and align columns to training reference\n",
    "Xdf = pd.concat(X_rows, axis=0, ignore_index=True).set_index(\"file\")\n",
    "# Add missing columns as zeros, drop extras, then reorder\n",
    "for c in cols_ref:\n",
    "    if c not in Xdf.columns:\n",
    "        Xdf[c] = 0.0\n",
    "extra = [c for c in Xdf.columns if c not in cols_ref]\n",
    "if extra:\n",
    "    Xdf = Xdf.drop(columns=extra)\n",
    "Xdf = Xdf[cols_ref]\n",
    "\n",
    "# Predict probabilities\n",
    "probs = clf.predict_proba(Xdf.to_numpy())\n",
    "kmax  = probs.argmax(axis=1)\n",
    "pmax  = probs[np.arange(len(pmax:=probs.max(axis=1))), kmax]\n",
    "pred_raw = [classes[k] for k in kmax]\n",
    "\n",
    "# Human label mapping and abstain\n",
    "def to_label(c):\n",
    "    if class_map:\n",
    "        return class_map.get(c, c)\n",
    "    return c\n",
    "\n",
    "pred_label = [to_label(c) if p >= TH_ABSTAIN else \"abstain\" for c, p in zip(pred_raw, pmax)]\n",
    "\n",
    "# Build output table\n",
    "prob_cols = {f\"p_{to_label(c)}\": probs[:, i] for i, c in enumerate(classes)}\n",
    "out = pd.DataFrame({\n",
    "    \"file\": Xdf.index,\n",
    "    \"pred\": pred_label,\n",
    "    \"p_max\": pmax,\n",
    "    \"raw_class\": [to_label(c) for c in pred_raw],\n",
    "    **prob_cols\n",
    "}).sort_values(\"file\")\n",
    "\n",
    "# Save CSV\n",
    "PRED_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(PRED_CSV, index=False)\n",
    "\n",
    "print(f\"Processed WAVs saved to: {OUT_DIR}\")\n",
    "print(f\"Predictions CSV:        {PRED_CSV}\")\n",
    "print(out.head(min(10, len(out))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
