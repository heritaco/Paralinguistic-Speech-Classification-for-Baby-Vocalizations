{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb50e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herie\\miniconda3\\envs\\psc\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed WAVs saved to: C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\processed\\Testing_data\n",
      "Predictions CSV:        C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\processed\\Testing_data\\predictions_testing.csv\n",
      "     file     pred     p_max  raw_class       p_1       p_2       p_3  \\\n",
      "0   1.wav        4  0.790200          4  0.064782  0.012788  0.006066   \n",
      "1  10.wav        2  0.633429          2  0.005956  0.633429  0.019739   \n",
      "2  11.wav        4  0.562059          4  0.000000  0.011775  0.004929   \n",
      "3  12.wav  abstain  0.497636          2  0.000000  0.497636  0.024416   \n",
      "4  13.wav        2  0.670719          2  0.000000  0.670719  0.007073   \n",
      "5  14.wav        5  0.732311          5  0.000000  0.000000  0.019601   \n",
      "6  15.wav        5  0.976580          5  0.000000  0.000000  0.023420   \n",
      "7  16.wav        2  0.800085          2  0.022618  0.800085  0.025428   \n",
      "8  17.wav        3  0.566158          3  0.342239  0.000000  0.566158   \n",
      "9  18.wav        4  0.801504          4  0.024155  0.019324  0.016993   \n",
      "\n",
      "        p_4       p_5  \n",
      "0  0.790200  0.126163  \n",
      "1  0.000000  0.340875  \n",
      "2  0.562059  0.421237  \n",
      "3  0.000000  0.477949  \n",
      "4  0.000000  0.322208  \n",
      "5  0.248087  0.732311  \n",
      "6  0.000000  0.976580  \n",
      "7  0.000000  0.151868  \n",
      "8  0.000000  0.091603  \n",
      "9  0.801504  0.138025  \n"
     ]
    }
   ],
   "source": [
    "# %pip install -U pandas numpy scikit-learn pydub opensmile joblib\n",
    "\n",
    "from pathlib import Path\n",
    "import glob, json\n",
    "import numpy as np, pandas as pd, joblib\n",
    "from pydub import AudioSegment, effects as FX\n",
    "import opensmile\n",
    "\n",
    "# ========= CONFIG ============================================================\n",
    "TEST_DIR   = Path(r\"C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\raw\\Testing_data\")\n",
    "OUT_DIR    = Path(r\"C:\\Users\\herie\\OneDrive - Fundacion Universidad de las Americas Puebla\\Proyectos\\En Proceso\\Paralinguistic Speech Classification for Human Vocalizations\\data\\processed\\Testing_data\")\n",
    "MODEL_PATH = Path(\"infantcry_eGeMAPS_logreg.joblib\")  # from previous training\n",
    "PRED_CSV   = OUT_DIR / \"predictions_testing.csv\"\n",
    "\n",
    "# Audio processing (must match training)\n",
    "TARGET_SR  = 16_000           # Hz\n",
    "TARGET_SW  = 2                # 16-bit\n",
    "MAKE_MONO  = True\n",
    "HPF, LPF   = 150, 6000        # Hz\n",
    "GATE_K     = 1.5              # gate threshold = K * RMS\n",
    "NORM_MODE  = \"rms\"            # \"peak\" or \"rms\"\n",
    "TARGET_RMS = 0.1\n",
    "TH_ABSTAIN = 0.55\n",
    "EPS        = 1e-12\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= HELPERS ===========================================================\n",
    "def clean_seg(seg: AudioSegment) -> AudioSegment:\n",
    "    if HPF: seg = FX.high_pass_filter(seg, HPF)\n",
    "    if LPF: seg = FX.low_pass_filter(seg, LPF)\n",
    "    return seg\n",
    "\n",
    "def seg_to_float(seg: AudioSegment):\n",
    "    if MAKE_MONO and seg.channels != 1: seg = seg.set_channels(1)\n",
    "    if TARGET_SR   and seg.frame_rate != TARGET_SR: seg = seg.set_frame_rate(TARGET_SR)\n",
    "    if TARGET_SW   and seg.sample_width != TARGET_SW: seg = seg.set_sample_width(TARGET_SW)\n",
    "    sr = seg.frame_rate; sw = seg.sample_width\n",
    "    arr = np.array(seg.get_array_of_samples())\n",
    "    peak = float(1 << (8*sw - 1))  # 32768 for 16-bit\n",
    "    y = arr.astype(np.float32) / peak\n",
    "    return y, sr\n",
    "\n",
    "def gate(y: np.ndarray, k: float) -> np.ndarray:\n",
    "    rms = float(np.sqrt(np.mean(y**2) + EPS))\n",
    "    thr = k * rms\n",
    "    y2 = y.copy()\n",
    "    y2[np.abs(y2) < thr] = 0.0\n",
    "    return y2\n",
    "\n",
    "def normalize(y: np.ndarray, mode: str, target_rms: float) -> np.ndarray:\n",
    "    if mode == \"peak\":\n",
    "        m = float(np.max(np.abs(y)) + EPS)\n",
    "        return y / m\n",
    "    rms = float(np.sqrt(np.mean(y**2) + EPS))\n",
    "    y2  = y * (target_rms / rms)\n",
    "    return np.clip(y2, -1.0, 1.0)\n",
    "\n",
    "def float_to_seg(y: np.ndarray, sr: int) -> AudioSegment:\n",
    "    y16 = np.clip(y * 32767.0, -32768, 32767).astype(np.int16)\n",
    "    return AudioSegment(y16.tobytes(), frame_rate=int(sr), sample_width=2, channels=1)\n",
    "\n",
    "# ========= LOAD MODEL ========================================================\n",
    "bundle = joblib.load(MODEL_PATH)\n",
    "clf      = bundle[\"model\"]                     # CalibratedClassifierCV\n",
    "cols_ref = bundle[\"columns\"]                   # training feature columns order\n",
    "class_map = bundle.get(\"class_map\", None)      # optional numeric->text map\n",
    "classes = clf.classes_.tolist()                # model's class labels (e.g., [1,2,3,4,5])\n",
    "\n",
    "# openSMILE extractor (eGeMAPSv02 Functionals)\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "# ========= PROCESS + FEATURE + PREDICT ======================================\n",
    "wav_paths = sorted(glob.glob(str(TEST_DIR / \"*.wav\")))\n",
    "assert wav_paths, f\"No WAVs found in {TEST_DIR}\"\n",
    "\n",
    "records = []\n",
    "X_rows, idx = [], []\n",
    "\n",
    "for p in wav_paths:\n",
    "    p = Path(p)\n",
    "    # 1) load + clean + gate + normalize\n",
    "    seg = AudioSegment.from_file(str(p))\n",
    "    seg = clean_seg(seg)\n",
    "    y, sr = seg_to_float(seg)\n",
    "    y = gate(y, GATE_K)\n",
    "    y = normalize(y, NORM_MODE, TARGET_RMS)\n",
    "\n",
    "    # 2) save processed wav\n",
    "    seg_out = float_to_seg(y, sr)\n",
    "    out_path = OUT_DIR / p.name\n",
    "    seg_out.export(str(out_path), format=\"wav\")\n",
    "\n",
    "    # 3) extract features on processed wav\n",
    "    feat = smile.process_file(str(out_path))  # 1-row DataFrame\n",
    "    feat[\"file\"] = p.name\n",
    "    X_rows.append(feat.reset_index(drop=True))\n",
    "    idx.append(p.name)\n",
    "\n",
    "# Stack features and align columns to training reference\n",
    "Xdf = pd.concat(X_rows, axis=0, ignore_index=True).set_index(\"file\")\n",
    "# Add missing columns as zeros, drop extras, then reorder\n",
    "for c in cols_ref:\n",
    "    if c not in Xdf.columns:\n",
    "        Xdf[c] = 0.0\n",
    "extra = [c for c in Xdf.columns if c not in cols_ref]\n",
    "if extra:\n",
    "    Xdf = Xdf.drop(columns=extra)\n",
    "Xdf = Xdf[cols_ref]\n",
    "\n",
    "# Predict probabilities\n",
    "probs = clf.predict_proba(Xdf.to_numpy())\n",
    "kmax  = probs.argmax(axis=1)\n",
    "pmax  = probs[np.arange(len(pmax:=probs.max(axis=1))), kmax]\n",
    "pred_raw = [classes[k] for k in kmax]\n",
    "\n",
    "# Human label mapping and abstain\n",
    "def to_label(c):\n",
    "    if class_map:\n",
    "        return class_map.get(c, c)\n",
    "    return c\n",
    "\n",
    "pred_label = [to_label(c) if p >= TH_ABSTAIN else \"abstain\" for c, p in zip(pred_raw, pmax)]\n",
    "\n",
    "# Build output table\n",
    "prob_cols = {f\"p_{to_label(c)}\": probs[:, i] for i, c in enumerate(classes)}\n",
    "out = pd.DataFrame({\n",
    "    \"file\": Xdf.index,\n",
    "    \"pred\": pred_label,\n",
    "    \"p_max\": pmax,\n",
    "    \"raw_class\": [to_label(c) for c in pred_raw],\n",
    "    **prob_cols\n",
    "}).sort_values(\"file\")\n",
    "\n",
    "# Save CSV\n",
    "PRED_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(PRED_CSV, index=False)\n",
    "\n",
    "print(f\"Processed WAVs saved to: {OUT_DIR}\")\n",
    "print(f\"Predictions CSV:        {PRED_CSV}\")\n",
    "print(out.head(min(10, len(out))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acaf9710",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
