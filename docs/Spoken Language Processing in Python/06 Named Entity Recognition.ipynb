{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4164b080",
   "metadata": {},
   "source": [
    "# SpaCy NER: single-pass entity extraction on a transcript string\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00578535",
   "metadata": {},
   "source": [
    "**Purpose.** Add named-entity extraction to transcripts using spaCy.\n",
    "\n",
    "| Component | Role                     | Why it matters                                         |\n",
    "| --------- | ------------------------ | ------------------------------------------------------ |\n",
    "| spaCy     | NLP toolkit              | Fast NER with easy pipelines                           |\n",
    "| Entity    | Labeled real-world thing | Pulls people, products, places, dates from text        |\n",
    "| Pipeline  | Ordered processors       | Control what runs and when (tagger, parser, ner, etc.) |\n",
    "\n",
    "**Setup.** Install spaCy and a language model.\n",
    "\n",
    "| Step           | Command                                   | Note                                |\n",
    "| -------------- | ----------------------------------------- | ----------------------------------- |\n",
    "| Install        | `pip install spacy`                       | Once per environment                |\n",
    "| Download model | `python -m spacy download en_core_web_sm` | Use `*_md`/`*_lg` for larger models |\n",
    "\n",
    "**Core objects.** How spaCy structures text.\n",
    "\n",
    "| Object  | Meaning                          | Accessors                                           |\n",
    "| ------- | -------------------------------- | --------------------------------------------------- |\n",
    "| `Doc`   | Processed text container         | `doc.text`, `doc.ents`, `doc.sents`, iterate tokens |\n",
    "| `Token` | Single lexical unit              | `token.text`, `token.idx`                           |\n",
    "| `Span`  | Slice of tokens (e.g., sentence) | `span.text`, `span.start`, `span.end`               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec320a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Acme', 0), ('shipped', 5), ('my', 13), ('smartphone', 16), ('to', 27), ('Sydney', 30), ('on', 37), ('3', 40), ('Oct.', 42), ('Thank', 47), ('you', 53), ('.', 56)]\n",
      "['Acme shipped my smartphone to Sydney on 3 Oct. Thank you.']\n"
     ]
    }
   ],
   "source": [
    "# Minimal: load model, build a Doc, view tokens and sentences\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # load model\n",
    "doc = nlp(\"Acme shipped my smartphone to Sydney on 3 Oct. Thank you.\")\n",
    "\n",
    "print([ (t.text, t.idx) for t in doc ])       # tokens with start indices\n",
    "print([ s.text for s in doc.sents ])          # sentence spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10cac9d",
   "metadata": {},
   "source": [
    "\n",
    "**Built-in NER.** Extract entities and inspect labels.\n",
    "\n",
    "| Access                   | Returns                | Example labels                         |\n",
    "| ------------------------ | ---------------------- | -------------------------------------- |\n",
    "| `doc.ents`               | iterable of entities   | `PERSON, ORG, GPE, DATE, PRODUCT, ...` |\n",
    "| `ent.text`, `ent.label_` | surface form and label | `\"Sydney\" → GPE`, `\"3 Oct\" → DATE`     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3b3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Sydney, Label: GPE\n",
      "Entity: 3 Oct., Label: DATE\n"
     ]
    }
   ],
   "source": [
    "# Named entities from a Doc\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce948f",
   "metadata": {},
   "source": [
    "**Custom entities via rules.** Add domain terms with `EntityRuler`.\n",
    "\n",
    "| Step             | API                                          | Purpose                              |\n",
    "| ---------------- | -------------------------------------------- | ------------------------------------ |\n",
    "| Create ruler     | `nlp.add_pipe(\"entity_ruler\", before=\"ner\")` | Insert before statistical NER        |\n",
    "| Add patterns     | `ruler.add_patterns([...])`                  | Rule labels for products, SKUs, etc. |\n",
    "| Inspect pipeline | `nlp.pipe_names`                             | Confirm `entity_ruler` is active     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44527fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'entity_ruler', 'ner']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('smartphone', 'PRODUCT')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Add a rule: label \"smartphone\" as PRODUCT before ner runs (ner nouns are statistical models that may miss domain-specific terms)\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}]) # add patterns, this is useful for example for domain-specific terms, in this case a product\n",
    "\n",
    "print(nlp.pipe_names)  # e.g., ['tok2vec', 'tagger', 'parser', 'entity_ruler', 'ner'] # confirm entity_ruler is active\n",
    "\n",
    "doc = nlp(\"The smartphone arrived late.\")\n",
    "[(ent.text, ent.label_) for ent in doc.ents]  # -> [('smartphone', 'PRODUCT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b5450",
   "metadata": {},
   "source": [
    "\n",
    "**Pipeline control.** Keep order deterministic for reliable outputs.\n",
    "\n",
    "| Desired effect                     | Placement                       | Rationale                             |\n",
    "| ---------------------------------- | ------------------------------- | ------------------------------------- |\n",
    "| Rules override or complement model | `entity_ruler` **before** `ner` | Ensure rule annotations are preserved |\n",
    "| Pure model behavior                | No ruler or `after=\"ner\"`       | Use statistical NER only              |\n",
    "\n",
    "**Usage in your project.** Apply to transcripts post-ASR.\n",
    "\n",
    "| Stage       | Action                                   | Output                      |\n",
    "| ----------- | ---------------------------------------- | --------------------------- |\n",
    "| Transcripts | Feed text to `nlp`                       | `Doc`                       |\n",
    "| Extract     | `[(e.text, e.label_) for e in doc.ents]` | Entities for analytics      |\n",
    "| Customize   | Add product/brand rules                  | Better recall on Acme terms |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
